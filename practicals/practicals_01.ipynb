{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2a03c2c",
   "metadata": {},
   "source": [
    "# Single-cell RNA-seqs analysis using Python  \n",
    "## Practicals 01: Raw reads to expression matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7455f290",
   "metadata": {},
   "source": [
    "Adapted from:  \n",
    "Single-cell best practices  \n",
    "www.sc-best-practices.org"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21bca12",
   "metadata": {},
   "source": [
    "## 1. Raw data processing\n",
    "Generate a cellxgene matrix from raw reads, using the tool `alevin-fry` to execute the final quantification of transcripts per cell.  \n",
    "\n",
    "The commands in this section are supposed to be exectued in a command-line terminal.  Lines that begin with a hash/pound sign are comment lines, and not meant to be run.  \n",
    "\n",
    "A script version of the commands below is also provided in (see `practicals_01.1.sh`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce4d4fb",
   "metadata": {},
   "source": [
    "### 1.1. Prepare the environment  \n",
    "The conda environment with the needed tools has been created for you.  Activate it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743ba8c0",
   "metadata": {},
   "source": [
    "```\n",
    "cd ~/scrnaseq_python_2023/practicals\n",
    "conda activate af\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2807fc4a",
   "metadata": {},
   "source": [
    "### 1.2. Get the data  \n",
    "The data for this training are already provided in `~/training_data`.  Set the path variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bc5a2b",
   "metadata": {},
   "source": [
    "```\n",
    "# The folder containing the fastq files is called toy_read_fastq.\n",
    "fastq_dir=\"../../training_data/toy_read_fastq\"\n",
    "\n",
    "# The folder containing the human ref files is called toy_human_ref.\n",
    "ref_dir=\"../../training_data/toy_human_ref\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdde8664",
   "metadata": {},
   "source": [
    "### 1.3. Build the reference index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a2dfeb",
   "metadata": {},
   "source": [
    "First, make a \"splici\" (spliced + intronic) extended transcriptome reference using `pyroe`.  Then, index the reference using `salmon index`.  \n",
    "\n",
    "Usage of `pyroe make-splici` is:  \n",
    "`pyroe make-splici genome_file gtf_file read_length out_dir`  \n",
    "(refer to the [`pyroe` documentation](https://pyroe.readthedocs.io/en/latest/building_splici_index.html#preparing-a-spliced-intronic-transcriptome-reference))\n",
    "\n",
    "- The `genome_file` is the reference genome sequence in fasta format.  \n",
    "- The `gtf_file` is the reference annotation file in gtf format.  It should have the transcript and gene annotations.  \n",
    "- The `read_length` is the number of sequencing cycles performed by the sequencer, and is the length of the biologically relevant read. Refer to the sequence provider for info on this; the 10X site also has [a page for this](https://www.10xgenomics.com/support/single-cell-gene-expression/documentation/steps/sequencing/sequencing-requirements-for-single-cell-3).  \n",
    "- `out_dir` is the output directory.\n",
    "\n",
    "Usage of `salmon index` is:  \n",
    "`salmon index -t extend_txome.fa -i idx_out_dir -p num_threads`. \n",
    "- `extend_txome.fa` is the extended transcriptome fasta output of pyroe.  \n",
    "- `idx_out_dir` is where you'd like the indexed reference to be written.  \n",
    "- `num_threads` is how many threads you'd like to use to run indexing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58913a96",
   "metadata": {},
   "source": [
    "```\n",
    "pyroe make-splici \\\n",
    "${ref_dir}/fasta/genome.fa \\\n",
    "${ref_dir}/genes/genes.gtf \\\n",
    "90 \\\n",
    "splici_rl90_ref\n",
    "\n",
    "salmon index \\\n",
    "-t $(ls splici_rl90_ref/*\\.fa) \\\n",
    "-i salmon_index \\\n",
    "-p 8\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb631e0",
   "metadata": {},
   "source": [
    "### 1.4. Perform mapping and quantification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd140a0e-14b4-49f6-b6f3-8aa2a4ef1005",
   "metadata": {},
   "source": [
    "#### 1.4.1. Map without quantification\n",
    "Usage is:  \n",
    "`salmon alevin -i index_dir -l library_type -1 reads1_files -2 reads2_files -p num_threads -o output_dir`  \n",
    "(refer to the [Alevin documentation](https://salmon.readthedocs.io/en/latest/alevin.html))  \n",
    "\n",
    "Important parameters to note include the fragment library type `-l` which different characteristics of reads1 and reads2.  More information about fragment library type can be found [here](https://salmon.readthedocs.io/en/latest/library_type.html).  Protocol should also be correctly provided.  Here, `--chromiumV3` indicates that the 10X Chromium v3 protocol was used during library preparation.  Other flags are available for other protocols, and `--custom` can be indicated for other protocols.  `--sketch` indicates that mapping will be performed but quantification will be skipped."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cc2f90",
   "metadata": {},
   "source": [
    "```\n",
    "salmon alevin \\\n",
    "-i salmon_index \\\n",
    "-l ISR \\\n",
    "-1 ${fastq_dir}/selected_R1_reads.fastq \\\n",
    "-2 ${fastq_dir}/selected_R2_reads.fastq \\\n",
    "-p 8 \\\n",
    "-o salmon_alevin \\\n",
    "--chromiumV3 \\\n",
    "--sketch\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d23ad09-abe1-40c6-be91-b969bc002ccc",
   "metadata": {},
   "source": [
    "#### 1.4.2. Cell barcode permit list generation\n",
    "To perform cell barcode correction, first, generate a list of filtered barcodes that should be included in the quantification.  \n",
    "Usage is:  \n",
    "`alevin-fry generate-permit-list -u CB_permit_list -d expected_orientation -i index_dir -o gpl_out_dir`  \n",
    "(refer to the [command documentation](https://alevin-fry.readthedocs.io/en/latest/generate_permit_list.html))  \n",
    "\n",
    "- `-d fw` indicates that valid reads should map to the fw strand of transcripts  \n",
    "- `CB_permit_list` is the file that lists all possible cell barcodes for that library preparation (provided by manufacturer).  Other protocols do not have this, in which case another way of generating a barcode permit list should be used, e.g., `--knee-distance`.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4820295f",
   "metadata": {},
   "source": [
    "```\n",
    "alevin-fry generate-permit-list \\\n",
    "-u \"../../training_data/3M-february-2018.txt\" \\\n",
    "-d fw \\\n",
    "-i salmon_alevin \\\n",
    "-o alevin_fry_gpl\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20dd4bd",
   "metadata": {},
   "source": [
    "Sample output of generating permit list:\n",
    "\n",
    "```\n",
    "2023-08-11 10:55:18 INFO number of unfiltered bcs read = 6,794,880\n",
    "2023-08-11 10:55:18 INFO paired : false, ref_count : 337, num_chunks : 7\n",
    "2023-08-11 10:55:18 INFO read 2 file-level tags\n",
    "2023-08-11 10:55:18 INFO read 2 read-level tags\n",
    "2023-08-11 10:55:18 INFO read 1 alignemnt-level tags\n",
    "2023-08-11 10:55:18 INFO File-level tag values FileTags { bclen: 16, umilen: 12 }\n",
    "2023-08-11 10:55:18 INFO observed 33,206 reads (18,985 orientation consistent) in 7 chunks --- max ambiguity read occurs in 24 refs\n",
    "2023-08-11 10:55:18 INFO minimum num reads for barcode pass = 10\n",
    "2023-08-11 10:55:18 INFO num_passing = 139\n",
    "2023-08-11 10:55:18 INFO found 139 cells with non-trivial number of reads by exact barcode match\n",
    "2023-08-11 10:55:18 INFO There were 893 distinct unmatched barcodes, and 151 that can be recovered\n",
    "2023-08-11 10:55:18 INFO Matching unmatched barcodes to retained barcodes took 175.209µs\n",
    "2023-08-11 10:55:18 INFO Of the unmatched barcodes\n",
    "============\n",
    "2023-08-11 10:55:18 INFO \t195 had exactly 1 single-edit neighbor in the retained list\n",
    "2023-08-11 10:55:18 INFO \t49 had >1 single-edit neighbor in the retained list\n",
    "2023-08-11 10:55:18 INFO \t1,586 had no neighbor in the retained list\n",
    "2023-08-11 10:55:18 INFO total number of distinct corrected barcodes : 151\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29c8a9e-825d-4275-8dc9-47c51352394b",
   "metadata": {},
   "source": [
    "#### 1.4.3.  Cell barcode filtering  \n",
    "The second step of cell barcode correction is using the generated barcode permit list to filter the mapping information.  \n",
    "Usage is:  \n",
    "`alevin-fry collate -i gpl_out_dir -r alevin_map_dir -t num_threads`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e698698",
   "metadata": {},
   "source": [
    "```\n",
    "alevin-fry collate \\\n",
    "-i alevin_fry_gpl \\\n",
    "-r salmon_alevin \\\n",
    "-t 8\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef355dc",
   "metadata": {},
   "source": [
    "Sample output of filter mapping:  \n",
    "\n",
    "```\n",
    "2023-08-11 10:56:58 INFO filter_type = Unfiltered\n",
    "2023-08-11 10:56:58 INFO collated rad file will not be compressed\n",
    "2023-08-11 10:56:58 INFO paired : false, ref_count : 337, num_chunks : 7, expected_ori : Forward\n",
    "2023-08-11 10:56:58 INFO read 2 file-level tags\n",
    "2023-08-11 10:56:58 INFO read 2 read-level tags\n",
    "2023-08-11 10:56:58 INFO read 1 alignemnt-level tags\n",
    "2023-08-11 10:56:58 INFO File-level tag values FileTags { bclen: 16, umilen: 12 }\n",
    "2023-08-11 10:56:58 INFO deserialized correction map of length : 290\n",
    "2023-08-11 10:56:58 INFO Generated 1 temporary buckets.\n",
    "  [00:00:00] [╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢]       7/7       partitioned records into temporary files.                                                                                                       [00:00:00] [╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢]       1/1       gathered all temp files.                                                                                                                      2023-08-11 10:56:58 INFO writing num output chunks (139) to header\n",
    "2023-08-11 10:56:58 INFO expected number of output chunks 139\n",
    "2023-08-11 10:56:58 INFO finished collating input rad file \"salmon_alevin/map.rad\".\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013e5a0e-130c-4d79-8d2c-03e41a23e2fa",
   "metadata": {},
   "source": [
    "#### 1.4.4. UMI resolution + quantification  \n",
    "Usage: \n",
    "`alevin-fry quant -r resolution -m txp_to_gene_mapping -i gpl_out_dir -o quant_out_dir -t num_threads`  \n",
    "(refer to [documentation](https://alevin-fry.readthedocs.io/en/latest/quant.html) for more information on the parameters)\n",
    "\n",
    "- `-r` refers to the method used for UMI resolution  \n",
    "- `-m` is the transcript-to-gene map file (the file that ends with `3col.tsv` in the splici generation output folder), and contains target or transcript ID, gene feature ID, splice status.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6cd4e5",
   "metadata": {},
   "source": [
    "```\n",
    "alevin-fry quant \\\n",
    "-r cr-like \\\n",
    "-m $(ls splici_rl90_ref/*3col.tsv) \\\n",
    "-i alevin_fry_gpl \\\n",
    "-o alevin_fry_quant \\\n",
    "-t 8\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78981b3",
   "metadata": {},
   "source": [
    "Sample stdout of above command:  \n",
    "\n",
    "```\n",
    "2023-08-11 10:57:48 INFO quantifying from uncompressed, collated RAD file File { fd: 4, path: \"/Users/irisyu/Library/CloudStorage/GoogleDrive-irisyu@ebi.ac.uk/My Drive/Notes/Notebooks/trainings/scrnaseq_python_2023/af_xmpl_run/alevin_fry_gpl/map.collated.rad\", read: true, write: false }\n",
    "2023-08-11 10:57:48 INFO paired : false, ref_count : 337, num_chunks : 139\n",
    "2023-08-11 10:57:48 INFO tg-map contained 20 genes mapping to 337 transcripts.\n",
    "2023-08-11 10:57:48 INFO read 2 file-level tags\n",
    "2023-08-11 10:57:48 INFO read 2 read-level tags\n",
    "2023-08-11 10:57:48 INFO read 1 alignemnt-level tags\n",
    "2023-08-11 10:57:48 INFO File-level tag values FileTags { bclen: 16, umilen: 12 }\n",
    "  [00:00:00] [╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢╢]     139/139     finished quantifying 139 cells.                                                                                                               2023-08-11 10:57:48 INFO processed 17,350 total read records\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e431a29d-537a-4e6c-884e-d138f7fd418e",
   "metadata": {},
   "source": [
    "Inspect the quantification result files in `alevin_fry_quant/alevin`.  \n",
    "```\n",
    "% tail -3 alevin_fry_quant/alevin/quants_mat.mtx  \n",
    "138 58 1\n",
    "139 9 1\n",
    "139 37 1\n",
    "% tail -3 alevin_fry_quant/alevin/quants_mat_rows.txt \n",
    "TTCGATTTCCGCTTAC\n",
    "TGCTCGTGTTCGAAGG\n",
    "ACTGTGAAGAAATTGC\n",
    "% tail -3 alevin_fry_quant/alevin/quants_mat_cols.txt \n",
    "ENSG00000120705-A\n",
    "ENSG00000198961-A\n",
    "ENSG00000245526-A\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efbc978-1128-489e-887b-d7c8aae8e075",
   "metadata": {},
   "source": [
    "__Optional for this demo__  \n",
    "You may load your alevin-fry results as an annData object with below command.  To try below, your notebook must be open in an env with `pyroe`.  \n",
    "```\n",
    "conda activate pyroe\n",
    "```\n",
    "And then uncomment all the commands (they have been commented out in the cells below so you don't accidentally run them)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3ce54b-5352-4ae8-b6f4-fbde82694d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pyroe\n",
    "\n",
    "# quant_dir = 'alevin_fry_quant'\n",
    "# adata_sa = pyroe.load_fry(quant_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05eaf1c-053e-4316-834c-e352be4f5889",
   "metadata": {},
   "source": [
    "Or, to include unspliced transcript variants in the count:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36850bee-2476-4350-a4f0-84f167a3fb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pyroe\n",
    "\n",
    "# quant_dir = 'alevin_fry_quant'\n",
    "# adata_usa = pyroe.load_fry(quant_dir, output_format={'X' : ['U','S','A']})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed610164-9e0a-47d5-bb31-b10486fc769a",
   "metadata": {},
   "source": [
    "More information about `pyroe.load_fry()` can be found [here](https://pypi.org/project/pyroe/0.7.1/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4571d5-cadd-4a2a-b8a7-147ffa960fdd",
   "metadata": {},
   "source": [
    "### Optional: Simpleaf method  \n",
    "The pipeline above can be run with fewer commands using the wrapper `simpleaf`.  However, it offers less flexibility.  Below summarizes the set of commands.  To run below in the command line, `simpleaf` must be installed. This wrapper is also installed in the conda env `af` that we provide in the VM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ea18d4-b783-42a9-92f3-53058dbae928",
   "metadata": {},
   "source": [
    "```\n",
    "conda activate af\n",
    "\n",
    "mkdir alevin_fry_home & export ALEVIN_FRY_HOME='alevin_fry_home'\n",
    "\n",
    "simpleaf set-paths\n",
    "\n",
    "simpleaf index \\\n",
    "-o simpleaf_index \\\n",
    "-f \"../../training_data/toy_human_ref/fasta/genome.fa\" \\\n",
    "-g \"../../training_data/toy_human_ref/genes/genes.gtf\" \\\n",
    "-r 90 \\\n",
    "-t 8\n",
    "\n",
    "simpleaf quant \\\n",
    "-c 10xv3 -t 8 \\\n",
    "-1 $reads1 -2 $reads2 \\\n",
    "-i simpleaf_index/index \\\n",
    "-u -r cr-like \\\n",
    "-m simpleaf_index/index/t2g_3col.tsv \\\n",
    "-o simpleaf_quant\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58e6de1",
   "metadata": {},
   "source": [
    "### Optional: Remove empty drops (Atlas method)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2631f65-37ff-42f2-b9da-4a036abef239",
   "metadata": {},
   "source": [
    "#### Convert from mtx to 10x  \n",
    "alevinFryMtxTo10x.py is a converter script that uses pyroe, with USA mode (use conda env `pyroe`).\n",
    "\n",
    "```\n",
    "(base) % conda activate pyroe\n",
    "(pyroe) % export PATH=~/scrnaseq_python_2023/bin:$PATH\n",
    "(pyroe) % alevinFryMtxTo10x.py alevin_fry_quant alevin_fry_parsed single_cell \n",
    "USA mode: True\n",
    "Using pre-defined output format: scrna\n",
    "Will populate output field X with sum of counts frorm ['S', 'A'].\n",
    "Will combine ['U'] into output layer unspliced.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274ea75d-b1fa-470b-abc1-93bd2b3d13d4",
   "metadata": {},
   "source": [
    "#### Remove empty drops  \n",
    "\n",
    "Below, use conda env with `bioconductor-dropletutils` and `dropletutils-scripts` (use conda env `dropletutils`).\n",
    "\n",
    "```\n",
    "(dropletutils) % dropletutils-read-10x-counts.R -s alevin_fry_parsed -c TRUE -o alevin_fry_parsed/matrix.rds\n",
    "...\n",
    "# Object summary\n",
    "class: SingleCellExperiment\n",
    "dim: 20 139\n",
    "metadata(0):\n",
    "assays(1): counts\n",
    "rownames(20): ENSG00000131507 ENSG00000131508 ... ENSG00000198961                                        \n",
    "  ENSG00000245526\n",
    "rowData names(2): ID Symbol\n",
    "colnames(139): ACTTTCAAGATCACCT GTGGAGACAATTAGGA ... TGCTCGTGTTCGAAGG                                    \n",
    "  ACTGTGAAGAAATTGC\n",
    "colData names(2): Sample Barcode\n",
    "reducedDimNames(0):\n",
    "spikeNames(0):\n",
    "\n",
    "# Metadata sample\n",
    "DataFrame with 6 rows and 2 columns\n",
    "                            Sample          Barcode\n",
    "                       <character>      <character>\n",
    "ACTTTCAAGATCACCT alevin_fry_parsed ACTTTCAAGATCACCT\n",
    "GTGGAGACAATTAGGA alevin_fry_parsed GTGGAGACAATTAGGA\n",
    "GTGTGGCGTAGTGTGG alevin_fry_parsed GTGTGGCGTAGTGTGG\n",
    "GTGGAGATCTTCCTAA alevin_fry_parsed GTGGAGATCTTCCTAA\n",
    "TTACAGGAGCTCTGTA alevin_fry_parsed TTACAGGAGCTCTGTA\n",
    "AGACACTTCGACGCGT alevin_fry_parsed AGACACTTCGACGCGT\n",
    "\n",
    "\n",
    "(dropletutils)[fg_atlas@hl-codon-101-03 af_xmpl_run]$ dropletutils-empty-drops.R -i alevin_fry_parsed/matrix.rds --lower 5 --niters 1000 --filter-empty TRUE --filter-fdr 0.01 -o empty_drops/nonempty.rds -t empty_drops/nonempty.txt                                               ...\n",
    "At an FDR of 0.01, estimate that 34 barcodes have cells.                                                 \n",
    "Will filter to 34 barcodes.\n",
    "\n",
    "Parameter values:\n",
    "             value\n",
    "lower            5\n",
    "niters        1000\n",
    "test_ambient FALSE\n",
    "filter_empty  TRUE\n",
    "filter_fdr    0.01\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637f1d68-760c-45ae-a662-a3e6011a4f99",
   "metadata": {},
   "source": [
    "#### Convert from RDS (SCE) to h5ad using sceasy\n",
    "\n",
    "Run below in an env with `r-sceasy`.  \n",
    "\n",
    "```\n",
    "(base) % conda activate sc_py_training\n",
    "\n",
    "(sc_py_training) % Rscript -e 'library(sceasy)' \\              \n",
    "-e 'sce <- readRDS(\"empty_drops/nonempty.rds\")' \\\n",
    "-e 'sceasy::convertFormat(sce, outFile=\"empty_drops/nonempty.h5ad\", from=\"sce\", to=\"anndata\", main_layer\n",
    "=\"counts\")' \\\n",
    "-e 'print(sce)'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680b3970",
   "metadata": {},
   "source": [
    "## 2.  Quality Control  \n",
    "Open this notebook in the `sc_py_training` conda env, before running the cells below.  \n",
    "```\n",
    "conda activate sc_py_training\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06d53a8-2e19-4a2e-bb05-871a0127b8f5",
   "metadata": {},
   "source": [
    "### 2.1. Filtering low quality barcodes  \n",
    "Filtering low quality barcodes minimizes the number of barcodes that do not represent single, live cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c2dea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import seaborn as sns\n",
    "from scipy.stats import median_abs_deviation\n",
    "\n",
    "sc.settings.verbosity = 0\n",
    "sc.settings.set_figure_params(\n",
    "    dpi=80,\n",
    "    facecolor=\"white\",\n",
    "    frameon=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ace9f8-0a1e-4b50-b497-592c6904bb76",
   "metadata": {},
   "source": [
    "We read in a pre-downloaded h5 data in 10X format (but a backup source link is provided)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b872f7d5-1129-4281-8e47-08cbc578949a",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_10x_h5(\n",
    "    filename=\"../../training_data/filtered_feature_bc_matrix.h5\",\n",
    "    backup_url=\"https://figshare.com/ndownloader/files/39546196\",\n",
    ")\n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a7c31c-a11f-40d7-8335-28aad5996eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.var_names_make_unique()\n",
    "adata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab78449-c225-4511-a49d-d2ab35a6fd64",
   "metadata": {},
   "source": [
    "The dataset has 16,934 barcodes and 36,601 transcripts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95870ea-afd7-4d09-9172-1b693029271f",
   "metadata": {},
   "source": [
    "Below, we add series of booleans to identify which variables (transcripts) are from mitochondrial, ribosomal, or hemoglobin genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa2c99c-ae8c-4f93-b924-56f0cf3eaee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mitochondrial genes\n",
    "adata.var[\"mt\"] = adata.var_names.str.startswith(\"MT-\")\n",
    "# ribosomal genes\n",
    "adata.var[\"ribo\"] = adata.var_names.str.startswith((\"RPS\", \"RPL\"))\n",
    "# hemoglobin genes.\n",
    "adata.var[\"hb\"] = adata.var_names.str.contains((\"^HB[^(P)]\"))\n",
    "adata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc5ac4b-7474-43ec-813d-b24e9315bef6",
   "metadata": {},
   "source": [
    "Notice that there are more columns now in `adata.var`.  \n",
    "\n",
    "Below, we calculate qc metrics using a predefined preprocessing function in scanpy, `scanpy.calculate_qc_metrics()`, which will evaluate the raw observations on a per-barcode basis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b862e2-662f-487d-92f8-8d332219a746",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.calculate_qc_metrics(\n",
    "    adata, qc_vars=[\"mt\", \"ribo\", \"hb\"], inplace=True, percent_top=[20], log1p=True\n",
    ")\n",
    "adata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1656c11-37d1-430d-9365-2f20cc397b96",
   "metadata": {},
   "source": [
    "Notice how we now have `adata.obs`, and the results of the qc metrics have been added to that dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334e21e9-a3c7-44bc-914e-73dc94103841",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3d20e0-0ffe-46b5-a32d-30a00acbb0bd",
   "metadata": {},
   "source": [
    "`scanpy` also has built-in plotting tools.  Let's use some of them to evaluate the qc metrics calculated above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8776850-44a1-4b3a-a4d6-a5a33d267b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ditribution of barcodes (cells) in terms of the number of transcripts per barcode (cell)\n",
    "p1 = sns.displot(adata.obs[\"total_counts\"], bins=100, kde=False)\n",
    "# To view above as a violon plot, try:\n",
    "# sc.pl.violin(adata, 'total_counts')\n",
    "\n",
    "# Distribution of barcodes (cells) in terms of the % mitochondrial transcripts per barcode (cell)\n",
    "p2 = sc.pl.violin(adata, \"pct_counts_mt\")\n",
    "\n",
    "# A scatter representing total_counts (x), n_genes_by_counts (y), and %mt of counts (color) per barcode (cell)\n",
    "p3 = sc.pl.scatter(adata, \"total_counts\", \"n_genes_by_counts\", color=\"pct_counts_mt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1870f6d-4c8f-4a03-a781-6e4657dcb95d",
   "metadata": {},
   "source": [
    "Next, using metrics we calculated above, let us identify outliers in our dataset.  Below defines a function that checks if an observation is an outlier based on `nmads * MAD` (where MAD is median absolute deviation).  The output is a series of booleans.  \n",
    "`MAD = median(|Xi-median(X)|)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719658f5-ecd1-44c7-8b42-7cba3cfe6ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_outlier(adata, metric: str, nmads: int):\n",
    "    M = adata.obs[metric]\n",
    "    outlier = (M < np.median(M) - nmads * median_abs_deviation(M)) | (\n",
    "        np.median(M) + nmads * median_abs_deviation(M) < M\n",
    "    )\n",
    "    return outlier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a1aee3-d794-4d58-aedf-d64e0dd44a1d",
   "metadata": {},
   "source": [
    "We want to tag as \"outlier\" those with counts that are more than 5 MADs from the median in the positive or negative direction (i.e., too far away from the median).  The metrics we look at are total counts (log-transformed), number of genes (log-transformed), and counts in the top 20 genes only (percent).  Below, `|` is a bitwise or operator comparing a 3 serieses of booleans (metrics).  If an observation (barcode) is an outlier in any of the three metrics, that barcode is tagged as an outlier.  We add this new information as a new column in our `adata.obs` dataframe, and we call that column `outlier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b882626-bfcb-4325-a868-968af20f0cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs[\"outlier\"] = (\n",
    "    is_outlier(adata, \"log1p_total_counts\", 5)\n",
    "    | is_outlier(adata, \"log1p_n_genes_by_counts\", 5)\n",
    "    | is_outlier(adata, \"pct_counts_in_top_20_genes\", 5)\n",
    ")\n",
    "adata.obs.outlier.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7ce8f5-da08-42e2-9182-9f4b3355e04e",
   "metadata": {},
   "source": [
    "We also apply the same function to identify outlier barcodes, based on the percent of mitochondrial transcripts.  We add this new information as a new column in our `adata.obs` dataframe, and we call that column `mt_outlier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef98a82-b671-43bc-9db7-04b615dcd69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs[\"mt_outlier\"] = is_outlier(adata, \"pct_counts_mt\", 3) | (\n",
    "    adata.obs[\"pct_counts_mt\"] > 8\n",
    ")\n",
    "adata.obs.mt_outlier.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0860e6c-1fca-418d-8e1a-7c8bde385011",
   "metadata": {},
   "source": [
    "Use outlier information to filter barcodes (cells).  Below, we use `~` which is a bitwise `not`, an inverse boolean mask (`True` to `False` and vice versa)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62f237e-5a5f-416e-8018-2737864bf453",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total number of cells: {adata.n_obs}\")\n",
    "adata = adata[(~adata.obs.outlier) & (~adata.obs.mt_outlier)].copy()\n",
    "print(f\"Number of cells after filtering of low quality cells: {adata.n_obs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9c294d-1c53-4b26-bfbd-26aed6ecb64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "p4 = sc.pl.scatter(adata, \"total_counts\", \"n_genes_by_counts\", color=\"pct_counts_mt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5344b9-b2df-4ec0-a326-8da53f5db1b8",
   "metadata": {},
   "source": [
    "We now have a smaller matrix (less barcodes).  We see that the ranges of the metrics are also now smaller.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c27df5-507e-447a-a130-fd0df3b48572",
   "metadata": {},
   "source": [
    "Save anndata to hda5, in case the Jupyter notebook kernel stops for any reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0475af03-b540-4cf4-ab5d-86d1124dc8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.write(\"../../training_data/s4d8_outliers_filtered_RNA.h5ad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a0e14d-55bd-43f2-b3a3-80b789d46e9c",
   "metadata": {},
   "source": [
    "#### 2.2 Correction of ambient RNA  \n",
    "This step attempts to remove or minimize the presence of free-floating or cell-free mRNA, the \"soup\".  Here, we'll use R in between Python cells, and the packages `anndata2ri` and `rpy2` help us do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0bab8a-0b23-4a88-bfd4-87a92f0977e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata2ri\n",
    "import logging\n",
    "\n",
    "import rpy2.rinterface_lib.callbacks as rcb\n",
    "import rpy2.robjects as ro\n",
    "\n",
    "rcb.logger.setLevel(logging.ERROR)\n",
    "ro.pandas2ri.activate()\n",
    "anndata2ri.activate()\n",
    "\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd52701e-bb90-49a5-a2c8-45ead9df077c",
   "metadata": {},
   "source": [
    "Load the R package we'll use to create a soup!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2d2689-cbd5-4403-b2df-fd630b5d0612",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "library(SoupX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c7cc4f-5e48-4b0e-832f-32d43388fc89",
   "metadata": {},
   "source": [
    "We create a copy of `adata`, normalize and log-transform that copy.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900f6aec-154f-4399-8ea4-c901f8124b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_pp = adata.copy()\n",
    "sc.pp.normalize_per_cell(adata_pp)\n",
    "sc.pp.log1p(adata_pp)\n",
    "adata_pp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b1f4d1-2f1a-4da4-b7fe-ad45c544cc98",
   "metadata": {},
   "source": [
    "Notice that above command `sc.pp.log1p` adds `adata_pp.uns[\"log1p\"]` to the annData object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d81a8a-c3e3-40ff-839a-5908cf4262fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.pca(adata_pp)\n",
    "sc.pp.neighbors(adata_pp)\n",
    "sc.tl.leiden(adata_pp, key_added=\"soupx_groups\")\n",
    "adata_pp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39593c70-717b-4048-b386-c5b20d6d76ef",
   "metadata": {},
   "source": [
    "Notice that the above commands add the corresponding column to `adata_pp.uns`.  The `.tl.leiden()` command also adds the column `soupx_groups` to `adata_pp.obs`, and it indicates groups. \n",
    "\n",
    "The purpose of the previous 2 cells is to create clusters or groups which can be used as the soupx groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8089609-0428-4d6b-b4f2-691b94df3692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess variables for SoupX\n",
    "soupx_groups = adata_pp.obs[\"soupx_groups\"]\n",
    "soupx_groups.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fbcbf4-9eff-4e3b-8f04-adbadefb145e",
   "metadata": {},
   "outputs": [],
   "source": [
    "del adata_pp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afd6bb7-278e-4d57-89b1-e182ed83d378",
   "metadata": {},
   "source": [
    "We get the components of our processed counts matrix (tranposed)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baafb063-9133-452e-bc34-5d560389aca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cells = adata.obs_names\n",
    "genes = adata.var_names\n",
    "data = adata.X.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ee4e19-5a82-401d-b014-7f79ab671d7a",
   "metadata": {},
   "source": [
    "And we get a transposed form of the original raw (unprocessed) data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ae1d53-7ef9-4b36-ba9e-6cee27b22f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_raw = sc.read_10x_h5(\n",
    "    filename=\"../../training_data/raw_feature_bc_matrix.h5\",\n",
    "    backup_url=\"https://figshare.com/ndownloader/files/39546217\",\n",
    ")\n",
    "adata_raw.var_names_make_unique()\n",
    "data_tod = adata_raw.X.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e433e3f3-c25d-45d6-bf68-97e16c80b46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "del adata_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70e7c50-0e67-4056-9127-439504a23917",
   "metadata": {},
   "source": [
    "Basically, the code below uses soupX to create a soup expression profile based on empty droplets in the raw, unfiltered matrix.  Then, it estimates the contamination fraction per cell.  Lastly, it outputs a matrix of corrected counts with the ambient mRNA removed, `out`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6e8e00-a21e-429f-a59d-505aff29670d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i data -i data_tod -i genes -i cells -i soupx_groups -o out \n",
    "\n",
    "# specify row and column names of data\n",
    "rownames(data) = genes\n",
    "colnames(data) = cells\n",
    "# ensure correct sparse format for table of counts and table of droplets\n",
    "data <- as(data, \"sparseMatrix\")\n",
    "data_tod <- as(data_tod, \"sparseMatrix\")\n",
    "\n",
    "# Generate SoupChannel Object for SoupX \n",
    "sc = SoupChannel(data_tod, data, calcSoupProfile = FALSE)\n",
    "\n",
    "# Add extra meta data to the SoupChannel object\n",
    "soupProf = data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), counts = rowSums(data))\n",
    "sc = setSoupProfile(sc, soupProf)\n",
    "# Set cluster information in SoupChannel\n",
    "sc = setClusters(sc, soupx_groups)\n",
    "\n",
    "# Estimate contamination fraction\n",
    "sc  = autoEstCont(sc, doPlot=FALSE)\n",
    "# Infer corrected table of counts and rount to integer\n",
    "out = adjustCounts(sc, roundToInt = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7b4679-aa71-48ae-923f-5f8091e95dca",
   "metadata": {},
   "source": [
    "Save `out` as the new main counts matrix, `adata.X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7254a4fe-c08a-401b-a33c-c2e2acebb5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.layers[\"counts\"] = adata.X\n",
    "adata.layers[\"soupX_counts\"] = out.T\n",
    "adata.X = adata.layers[\"soupX_counts\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c351d247-5924-4633-81a2-290ce7406e83",
   "metadata": {},
   "source": [
    "After correcting the counts, remove genes that have less than x number of cells expressing them (x in this case is 20).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aefbaaf-dcc6-4b99-b3da-6f5247731c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total number of genes: {adata.n_vars}\")\n",
    "\n",
    "# Min 20 cells - filters out 0 count genes\n",
    "sc.pp.filter_genes(adata, min_cells=20)\n",
    "print(f\"Number of genes after cell filter: {adata.n_vars}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11db6de4-b07f-4244-a0cd-99c374ba3571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save above data, so as not to repeat all of above when kernel stops\n",
    "adata.write(\"../../training_data/s4d8_corrected_ambient_RNA.h5ad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d52632-25f7-448b-977b-bf8d914d994e",
   "metadata": {},
   "source": [
    "#### 2.3 Doublet Detection  \n",
    "A study that benchmarked different doublet detection methods found that the scDblFinder method gives the most accurate and most efficient doublet detection ([Xi and Li 2021](https://doi.org/https://doi.org/10.1016/j.cels.2020.11.008)).  ScDblFinder, in gist, generates a doublet expression profile by randomly selecting 2 barcodes and averaging their expression profiles.  It uses the artificial doublet model to identify potential doublets in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9741445-7a0d-491f-ae97-9f9be035a8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "library(Seurat)\n",
    "library(scater)\n",
    "library(scDblFinder)\n",
    "library(BiocParallel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec45c51a-fe47-4a61-bf75-2b8cac349f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mat = adata.X.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409292b2-6109-4011-98ae-b4791a0573b8",
   "metadata": {},
   "source": [
    "Below is the scDblFinder command that scores barcodes and classifies them according to singlets or doublets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfbf10f-a864-4fbf-b519-11f0ec5a1cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i data_mat -o doublet_score -o doublet_class\n",
    "\n",
    "set.seed(123)\n",
    "sce = scDblFinder(\n",
    "    SingleCellExperiment(\n",
    "        list(counts=data_mat),\n",
    "    ) \n",
    ")\n",
    "doublet_score = sce$scDblFinder.score\n",
    "doublet_class = sce$scDblFinder.class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38e64eb-2ab0-473d-a245-2397f0adf1e8",
   "metadata": {},
   "source": [
    "The doublet scores and classifications are added as attributes of `adata.obs`, the barcodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1e5dcf-de05-4f5d-bba8-42f570891977",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs[\"scDblFinder_score\"] = doublet_score\n",
    "adata.obs[\"scDblFinder_class\"] = doublet_class\n",
    "adata.obs.scDblFinder_class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23738db2-50af-40cb-8eb1-2a88f8424d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.write(\"../../training_data/s4d8_quality_control.h5ad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef9a917-0324-4f06-aa34-8b690bd339f7",
   "metadata": {},
   "source": [
    "### Note: Concatenating matrices from different batches  \n",
    "Concatenation of matrices should be done after QC, because different batches each have their own set of random sources of error that will need individual correction.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5a24d0-1cfe-4d49-afc1-d5b87e60bbc9",
   "metadata": {},
   "source": [
    "## 3. Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c613c33-9a8b-4946-a7d9-522e00934ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import anndata2ri\n",
    "import logging\n",
    "from scipy.sparse import issparse\n",
    "\n",
    "import rpy2.rinterface_lib.callbacks as rcb\n",
    "import rpy2.robjects as ro\n",
    "\n",
    "sc.settings.verbosity = 0\n",
    "sc.settings.set_figure_params(\n",
    "    dpi=80,\n",
    "    facecolor=\"white\",\n",
    "    # color_map=\"YlGnBu\",\n",
    "    frameon=False,\n",
    ")\n",
    "\n",
    "rcb.logger.setLevel(logging.ERROR)\n",
    "ro.pandas2ri.activate()\n",
    "anndata2ri.activate()\n",
    "\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6efaca-3a5a-4dac-9107-5451383dd940",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read(\n",
    "    filename=\"../../training_data/s4d8_quality_control.h5ad\",\n",
    "    backup_url=\"https://figshare.com/ndownloader/files/40014331\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811ed644-83bf-472d-93a7-46f6614b9694",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = sns.histplot(adata.obs[\"total_counts\"], bins=100, kde=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24057a6a-58c9-4a2c-96c2-bb1b6c516427",
   "metadata": {},
   "source": [
    "#### 3.1 Shifted logarithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53afdddf-095c-4d39-80f6-d0e1def0061a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scales_counts = sc.pp.normalize_total(adata, target_sum=None, inplace=False)\n",
    "# log1p transform\n",
    "adata.layers[\"log1p_norm\"] = sc.pp.log1p(scales_counts[\"X\"], copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fae84ec-34b3-4a1a-a453-3d2238de18e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "p1 = sns.histplot(adata.obs[\"total_counts\"], bins=100, kde=False, ax=axes[0])\n",
    "axes[0].set_title(\"Total counts\")\n",
    "p2 = sns.histplot(adata.layers[\"log1p_norm\"].sum(1), bins=100, kde=False, ax=axes[1])\n",
    "axes[1].set_title(\"Shifted logarithm\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2944b1-2a32-4e1d-a193-41136c3100e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix, issparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ba017e-fe57-42b6-b56f-65c229e0b91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "library(scran)\n",
    "library(BiocParallel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6155298b-a318-4167-8f0d-b76343fba742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preliminary clustering for differentiated normalisation\n",
    "adata_pp = adata.copy()\n",
    "sc.pp.normalize_total(adata_pp)\n",
    "sc.pp.log1p(adata_pp)\n",
    "sc.pp.pca(adata_pp, n_comps=15)\n",
    "sc.pp.neighbors(adata_pp)\n",
    "sc.tl.leiden(adata_pp, key_added=\"groups\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aac1ba0-54ee-4ba9-aaaf-3f4cb4462103",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mat = adata_pp.X.T\n",
    "if issparse(data_mat):\n",
    "    if data_mat.nnz > 2**31 - 1:\n",
    "        data_mat = data_mat.tocoo()\n",
    "    else:\n",
    "        data_mat = data_mat.tocsc()\n",
    "ro.globalenv[\"data_mat\"] = data_mat\n",
    "ro.globalenv[\"input_groups\"] = adata_pp.obs[\"groups\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213177ec-acd3-4ce8-b269-ca593f893a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "del adata_pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae1e56b-b7a2-4c8c-b219-37807a3cc461",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -o size_factors\n",
    "\n",
    "size_factors = sizeFactors(\n",
    "    computeSumFactors(\n",
    "        SingleCellExperiment(\n",
    "            list(counts=data_mat)), \n",
    "            clusters = input_groups,\n",
    "            min.mean = 0.1,\n",
    "            BPPARAM = MulticoreParam()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a49378-4276-4177-90eb-4367ed0596f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs[\"size_factors\"] = size_factors\n",
    "scran = adata.X / adata.obs[\"size_factors\"].values[:, None]\n",
    "adata.layers[\"scran_normalization\"] = csr_matrix(sc.pp.log1p(scran))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af28ea8-962c-46a2-b256-dd12b7d9dab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.write(\"../../training_data/s4d8_log1p_normalization.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c46387-532f-4b14-910a-5aa613628f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "p1 = sns.histplot(adata.obs[\"total_counts\"], bins=100, kde=False, ax=axes[0])\n",
    "axes[0].set_title(\"Total counts\")\n",
    "p2 = sns.histplot(\n",
    "    adata.layers[\"scran_normalization\"].sum(1), bins=100, kde=False, ax=axes[1]\n",
    ")\n",
    "axes[1].set_title(\"log1p with Scran estimated size factors\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136feb5a-e382-4a5c-b842-1cf5fbdad0e5",
   "metadata": {},
   "source": [
    "#### 3.2 Analytic Pearson Residuals (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00abb59-5013-4c12-99f0-5eac164f20e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this if kernel stops below\n",
    "# adata = sc.read(\"../../training_data/s4d8_log1p_normalization.h5ad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b6159a-6266-4331-bde2-f6030e46e342",
   "metadata": {},
   "source": [
    "Cell below is memory-intensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee651e9-49a1-4c94-9d3d-fa62ca170be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "analytic_pearson = sc.experimental.pp.normalize_pearson_residuals(adata, inplace=False)\n",
    "adata.layers[\"analytic_pearson_residuals\"] = csr_matrix(analytic_pearson[\"X\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad488e32-c47d-4aee-b75e-f04fa9dc533d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "p1 = sns.histplot(adata.obs[\"total_counts\"], bins=100, kde=False, ax=axes[0])\n",
    "axes[0].set_title(\"Total counts\")\n",
    "p2 = sns.histplot(\n",
    "    adata.layers[\"analytic_pearson_residuals\"].sum(1), bins=100, kde=False, ax=axes[1]\n",
    ")\n",
    "axes[1].set_title(\"Analytic Pearson residuals\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17aede63-78d7-4c7f-b11f-35a3e75d79fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.write(\"../../training_data/s4d8_normalization.h5ad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b28c86a-2886-47a9-97d1-f3781e11bee2",
   "metadata": {},
   "source": [
    "## 4. Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66081511-57ac-4f7e-bbdd-fe782b938f53",
   "metadata": {},
   "source": [
    "__Helpful tip:__  Some of the commands below are memory-intensive.  To avoid maxing out the VM's 32 GB RAM, export notebook with results to HTML first, then restart kernel before running this section again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f81108-f6ca-4f9d-991e-69a0382ac18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import anndata2ri\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import rpy2.rinterface_lib.callbacks as rcb\n",
    "import rpy2.robjects as ro\n",
    "\n",
    "sc.settings.verbosity = 0\n",
    "sc.settings.set_figure_params(\n",
    "    dpi=80,\n",
    "    facecolor=\"white\",\n",
    "    frameon=False,\n",
    ")\n",
    "\n",
    "rcb.logger.setLevel(logging.ERROR)\n",
    "ro.pandas2ri.activate()\n",
    "anndata2ri.activate()\n",
    "\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9af4b51-9597-41ea-83b6-aadcf048e06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "library(scry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328a329b-67c9-4f77-a1b5-44f9b3c5950e",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read(\n",
    "    filename=\"../../training_data/s4d8_log1p_normalization.h5ad\",\n",
    "    backup_url=\"https://figshare.com/ndownloader/files/40015741\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f190f2-4282-48ce-bccf-ee8651140bcf",
   "metadata": {},
   "source": [
    "Loading below is memory-intensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf74e814-bfbb-41b9-ab6f-e90ff771f26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ro.globalenv[\"adata\"] = adata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd74beaa-b0fd-4e91-98fc-a61d9f36706e",
   "metadata": {},
   "source": [
    "Computation below is memory-intensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec6941d-4824-41c7-8288-ca1e68152cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "sce = devianceFeatureSelection(adata, assay=\"X\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ae8162-4008-4d5b-922f-6f60cc452eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "binomial_deviance = ro.r(\"rowData(sce)$binomial_deviance\").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1a19af-c3e5-4e9c-acf2-82e9f9081bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = binomial_deviance.argsort()[-4000:]\n",
    "mask = np.zeros(adata.var_names.shape, dtype=bool)\n",
    "mask[idx] = True\n",
    "\n",
    "adata.var[\"highly_deviant\"] = mask\n",
    "adata.var[\"binomial_deviance\"] = binomial_deviance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c86716-8b42-4b60-a880-092cbdbdeb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.highly_variable_genes(adata, layer=\"scran_normalization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a608f2c4-dd4a-44d3-b568-2c8ba5812396",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(\n",
    "    data=adata.var, x=\"means\", y=\"dispersions\", hue=\"highly_deviant\", s=5\n",
    ")\n",
    "ax.set_xlim(None, 1.5)\n",
    "ax.set_ylim(None, 3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b158839-2699-4c35-b960-2fdae8a0408d",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.write(\"../../training_data/s4d8_feature_selection.h5ad\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
